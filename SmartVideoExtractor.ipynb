{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SmartVideoExtractor.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMAHI6XHqeoXpi82cu1xeI+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bxO0eRQVokDJ","colab_type":"code","colab":{}},"source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ri8kFsa5tXXm","colab_type":"code","colab":{}},"source":["!pip install face_recognition "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UnJojpKTDbdL","colab_type":"code","colab":{}},"source":["import cv2\n","import face_recognition\n","\n","input_movie = cv2.VideoCapture(\"InputVideo.mp4\")\n","length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","image = face_recognition.load_image_file(\"rock.jpg\")\n","face_encoding = face_recognition.face_encodings(image)[0]\n","\n","known_faces = [\n","face_encoding,\n","]\n","\n","# Initialize variables\n","face_locations = []\n","face_encodings = []\n","face_names = []\n","frame_number = 0\n","size = ( int(input_movie.get(cv2.CAP_PROP_FRAME_WIDTH)), int(input_movie.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n","out = cv2.VideoWriter('outputVideo.avi', cv2.VideoWriter_fourcc(*'DIVX'), int(input_movie.get(cv2.CAP_PROP_FPS)), size)\n","\n","\n","while True:\n","    # Grab a single frame of video\n","    ret, frame = input_movie.read()\n","    frame_number += 1\n","\n","    # Quit when the input video file ends\n","    if not ret:\n","        break\n","\n","    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n","    rgb_frame = frame[:, :, ::-1]\n","\n","    # Find all the faces and face encodings in the current frame of video\n","    face_locations = face_recognition.face_locations(rgb_frame, model=\"cnn\")\n","    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n","\n","    face_names = []\n","    for face_encoding in face_encodings:\n","        # See if the face is a match for the known face(s)\n","        match = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.50)\n","\n","        name = None\n","        if match[0]:\n","            name = \"Rock\"\n","\n","        face_names.append(name)\n","\n","    # Label the results\n","    for (top, right, bottom, left), name in zip(face_locations, face_names):\n","        if not name:\n","            continue\n","\n","        # Draw a box around the face\n","        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n","\n","        # Draw a label with a name below the face\n","        cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)\n","        font = cv2.FONT_HERSHEY_DUPLEX\n","        cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)        \n","        print(\"\\033[92m Writing Matching frame {} / {} \\033[0m\".format(frame_number, length))\n","        out.write(frame)\n","\n","    print(\"\\033[91m Skipping a Non Matching Frame {} / {} \\033[0m\".format(frame_number, length))\n","\n","input_movie.release()\n","cv2.destroyAllWindows()\n","out.release()"],"execution_count":0,"outputs":[]}]}